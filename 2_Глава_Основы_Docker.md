[Архитектура Docker](#Архитектура-Docker)<br>
[Как создаются образы](#Как-создаются-образы)<br>
[Установление связи контейнеров с внешним миром](#Установление-связи-контейнеров-с-внешним-миром)<br>
[Соединение между контейнерами](#Соединение-между-контейнерами)<br>
[Управление данными с помощью томов и контейнеров данных](#Управление-данными-с-помощью-томов-и-контейнеров-данных)<br>
[Часто используемые команды Docker](#Часто-используемые-команды-Docker)<br>
***
# Основы Docker

## Архитектура Docker

Чтобы понять как наиболее эффективно использовать Docker и некоторые не вполне
очевидные его свойства, необходимо хотя бы в целом представлять себе, каким образом организована совместная работа
компонентов платформы, скрытых от пользователя.

![](img/4.1.png)

- в центре расположен демон Docker (Docker daemon), ответственный за создание, запуск и контроль
  работы контейнеров, а так же за создание и хранение образов. Контейнеры и образы представлены в 
  правой части диаграммы. Демон Docker запускается командой `docker daemon`, обычно об этом заботится
  ОС хоста;


- клиент Docker, размещенный в левой части диаграммы, используется для диалога с демоном Docker по 
  протоколу HTTP. По умолчанию это соединение устанавливается через сокет домена Unix, но также может
  использоваться TCP-сокет для поддержки соединений с удаленными клиентами или дискриптор файла для 
  сокетов, управляемый `systemd`. Так как все затруднения организовать соединене с удаленным демонами
  Docker и разработать привязки (bindings) к нужному языку программирования, но при этом следует учитывать
  особенности реализации этих возможностей, например обязательное наличие контекста создания
  (building context), описанного в соответствующем разделе данной книги. Интерфейсы прикладного 
  программирования, используемые для организации обмена данными с демоном, четко определены и 
  подробно документированы, что позволяет разработчиками писать программы, взаимодействующие 
  напрямую с демоном, без использования клиента Docker. Клиент и демон Docker распространяются 
  как отдельные независимые бинарные файлы;


- реестры Docker используют для хранения и расположения образов. Реестром, выбираемым по умолчанию, является 
  Docker Hub, на котором хранится тысячи общедоступных образов, а так же управляемые "официальные" образы.
  Многие организации создают собственные реестры, которые используются для хранения коммерческих и приватных 
  образов и для устранения накладных расходов, связанных с загрузкой образов через интернет. В разделе
  "Создание собственного реестра" содержится более подробная информация об организации и сопровождении
  нового частного реестра. Демон Docker загружает образы из реестров по запросу `docker pull`. Кроме того, 
  он выполняет автоматическую загрузку образов, указанных в запросе `docker run` и в инструкции `FROM` файла
  Dockerfile, если эти образы недоступны на локальной системе.

### Базовые технологии

Демон Docker использует "драйвер выполнения" (execution driver) для создания контейнеров. По умолчанию выбирается
собственный драйвер Docker `runc`, но, кроме того, обеспечивается поддержка более старого драйвера для 
механизма LXC. Драйвер `runc` очень тесно связан со следующими механизмами ядра:
- `cgroups` - механизм, отвечающий за управление ресурсами, используемыми контейнером (процессор, ОЗУ и тд).
Механизм `cgroups` так же обеспечивает выполнение операции замораживания контейнеров как поддержку функциональности
команды `docker pause`;


- `пространство имен (namespaces)` отвечают за изоляцию контейнеров, гарантируют что файловая система, имя хоста, 
пользователи, сетевая среда и процессы любого контейнера полностью отделены от остальной части системы.


`Libcontainer` также поддерживает `SElinux` и `AppArmor`, которые можно использовать для создания
более строгой системы безопасности. 

Еще одной основополагающей технологией для Docker является файловая система с каскадно-объединенным монтированием
(Union File System - UnionFS), обеспечивающая хранение уровней для контейнеров. Функциональность UnionFS
обеспечивается одним из нескольких драйверов файловой системы: `AUFS`, `devicemapper`, `BTRFS` или `Overlay`.

### Сопровождающие технологии

Сами по себе механизмы Docker и реестр Docker Hub не представляют завершенного полноценного решения
для работы с контейнерами. Для большинства пользователей потребуются сервисы поддержки и вспомогательное ПО,
например система управления кластерами, инструменты обнаружения сервисов, расширенные сетевые функциональные 
возможности и проч. Docker Inc. планирует создания полноценного решения "из коробки", включающего все требуемые
возможности, но позволяющего пользователям без труда заменять компоненты, установленные по умолчанию, на компоненты
сторонних производителей. Стратегия "заменяемых батареек" в первую очередь реализуется на уровне интерфейсов 
прикладного программирования, позволяя подключать компоненты непосредственно к движку Docker, но её так же можно
наблюдать на формировании дистрибутивных пакетов Docker как независимых автономных бинарных файлов, которые с легкостью
заменяются аналогами от третьих сторон.


На текущий момент можно привести следующий список технологий поддержи, предоставляемых Docker:
- `Swarm` - решение задачи кластеризации от Docker. `Swarm` позволяет сгруппировать несколько Docker-хостов,
после чего пользователь может работать с этой группой как с единым ресурсом.


- `Docker Compose` - инструмент для создания и выполнения приложений, скомпонованных из нескольких
Docker-контейнеров. Такие компоновки используются главным образом при разработке и тестировании, но 
гораздо реже в производственной среде. 


- `Docker Maсhine` - устанавливает и конфигурирует Docker-хосты на локальных и удаленных ресурсах. Кроме того, 
Maсhine конфигурирует клиента Docker, упрощая процедуру переключения между средами.


`Kitematic` представляет собой графический пользовательский интерфейс для Mac OS и Windows, обеспечивающий 
запуск и управление контейнеров Docker.

`Docker Trusted Registry` - локально устанавливаемое программное решение для хранения и управления образами
Docker Hub, которую можно объединить с существующей инфраструктурой обеспечения безопасности и согласовать
с правилами хранения и обеспечения защиты данных, принятых в конкретной организации. Все функциональные
возможности локального реестра, в том числе различные метрики, управление доступом на основе ролей и 
регистрационные журналы, контролируются через административную консоль. В настоящий момент это единиственный
программный продукт Docker Inc., исходный код которого закрыт.

Список сервисов и приложений третьих сторон, которые основаны на Docker или используют эту платформу, уже 
сейчас достаточно велик. Некоторые полноценные решения доступны в следующих областях:

- `сетевая среда` - создание сетей контейнеров, распределенных между разными хостами, представляет собой
непростую задачу, которую можно решить разнообразными способами. Недавно в этой области появилось
несколько решений, например [Weave](http://weave.works/net/) и [Project Calico](http://www.projectcalico.org/).
Кроме того, Docker намерен в ближайшем будущем представить комплексно сетевое решение под названием Overlay.
Пользователи смогут заменить драйвер Overlay на любые другие решения, использую подключаемую программную
рабочую среду для работы в сети;


- `обнаружение сервисов` - сразу после появления контейнеров Docker потребовался способ поиска других 
сервисов для взаимодействия с ним. Обычно такие сервисы также работают в контейнерах. Поскольку IP-адреса
присваиваются контейнерам динамически, задача обнаружения сервисов в больших системах достаточно 
сложна. К решениям в этой области относятся [Consul](https://consul.io/), [Registrator](https://github.com/gliderlabs/registrator)
, [SkyDNS](https://github.com/skynetservices/skydns/) и [etcd](https://github.com/coreos/etcd);


- `орекстровка и управление кластером` - при развертывании большого количества контейнеров весьма важно
наличие инструментов для контроля и управления всех системой в целом. Каждый новый контейнер должен быть
размещен на некотором хосте, его нужно контролировать и обновлять. Система должна правильно реагировать
на сбои или изменения нагрузки, перемещая, запуск или останавливая контейнеры соответствующим образом.
Здесь можно отметить несколько конкурирующих решений: [Kubernetes](http://kubernetes.io) от Google,
[Marathon](https://github.com/me-sosphere/marathon); фреймворк для [Mesos](https://mesos.apache.org),
[Fleet](https://github.com/coreos/fleet) от CoreOS, а также собственный инструмент Docker Swarm.

В дополнении к выше упомянутым подключаемым сетевым драйверам Docker поддерживает еще и _подключаемые тома_
_(volume plugins)_ для интеграции с другими системами хранения данных. Здесь особого внимания заслуживает
[Flocker](https://github.com/ClusterHQ/flocker), инструмент для управления данными и их перемещения 
в многохостовой системе, и [GlusterFS](https://github.com/calavera/docker-volume-glusterfs) для 
распределенного хранения данных. Более подробную информацию о фреймворке подключаемых драйверов
можно найти на [сайте](https://docs.docker.com/extend/plugins/).

Широкое распространение контейнеров привело к любопытному побочному эффекту, заключающемуся в появлении
нового поколения ОС, специализированных для поддержки контейнеров. Несмотря на то что Docker успешно
работает на большинстве современных дистрибутивов Linux, таких как Ubuntu, Red Hat и других, появились
проекты, направленные на создание облегченных и простых в сопровождении дистрибутивов, главной задачей
которых является только обеспечение работы контейнеров (или контейнеров и виртуальных машин), что особенно
важно для расширения функциональных возможностей центра обработки данных или кластера. В качестве примеров
можно привести [Project Atomic](http://www.projectatomic.io/), [CoreOS](https://coreos.com/), [RancherOS](http://rancher.com/rancher-os/).

### Хостинг для Docker

Многие известные облачные драйвера, в том числе Amazon, Google и Digital Ocean, уже предлагают определенный 
уровень поддержки Docker. Google Container Engine, возможно, является самым интересным вариантом, так как
создан непосредственно на платформе Kubernetes. Разумеется, даже если облачный провайдер не предлагает
прямую поддержку Docker, обычно имеет возможность представления виртуальных машин, в которых можно 
запускать Docker-контейнеры.

В этой области так же работает компания Joyent, предлагающая собственный механизм контейнеров под названием
Triton на основе SmartOS. С помощью реализации интерфейсов прикладного программирования Docker в своем механизме
контейнеров и технологии эмуляции Linux компания Joyent смогла создать общедоступный облачный сервис,
взаимодействующий со стандартным Docker клиентом. Более того, компания Joyent уверена, что ее реализация 
контейнера обладает высоким уровнем безопасности, позволяющим работать непосредственно с аппаратным обеспечением,
без необходимости размещения в виртуальной машине, а это может означать более высокую эффективность и существенное
сокращение накладных расходов, особенно с точки зрения операций ввода/вывода. 

Есть еще несколько проектов, организовавших PaaS-платформу на основе Docker, - [Deis](http://paz.sh), [Flynn](http://paz.sh) и [Paz](http://paz.sh)

## Как создаются образы

В этом разделе будет более подробно описано все происходящее при создании образа, а в конце
раздела приведено краткое руководство по различным инструкциям, используемым в Dockerfile. Всегда 
полезно понимать внутреннее функционирование команды создания, так как ее поведение иногда может 
становиться неожиданным.

### Контекст создания образа

Для команды `docker build` необходим Dockerfile и _контекст создания образа (build context)_ который может
быть пустым. 

Контекст создания - это набор локальных файлов и каталогов, к которым можно обращаться из инструкций
`ADD` и\или `COPY` в Dockerfile и которые обычно определяются как путь к нужному каталогу. Например,
команда создания образа `docker build -t test\cowsay-dockerfile .`, которая определяла контекст создания
как `.`, то есть текущий рабочий каталог. Все файлы и каталоги, расположенные по указанному пути, формируют
контекст создания образа и передаются в демон Docker как часть процесса создания.

В тех случаях, когда контекст не определен, - если задан только URL для Dockerfile или содержимое 
Dockerfile переедается по программному каналу из стандартного потока `STDIN`, - контекст создания данного
образа считается пустым.

> **Не следует использовать / в качастве контекста создания образа**
> 
> Поскольку контекст создания образа полностью включает tar-архив и передается в демон Docker, 
> не используйте для этой цели каталога, в котором содержится большое кол-во файлов. Например,
> если для контекста создания вы возьмете /home/user, Загрузки (Downloads) или /, то в результате
> получите длинную задержку, пока Docker-клиент будет упаковывать все файлы заданного каталога 
> и передавать их в демон.

Если задан URL, начинающийся с http или https, то предполагается, что это прямая ссылка на Dockerfile.
Маловероятно, что это окажется полезным, так как с файлом Dockerfile не связан какой-либо контекст
(а ссылки на архивы неприемлемы).

В качестве контекста создания образа разрешается указывать git-репозиторий. В этом случае клиент Docker
создаст клон такого репозитория и всех подчиненных модулей во временном каталоге, который затем 
передается в демон Docker как контекст создания образа. Docker воспринимает контекст как git-репозиторий,
если переданный путь начинается с префиксов `github.com/`, `git@` или `git://`. Вообще говоря, я рекомендую
избегать применения такого метода, вместо этого лучше перечислять репозиторий вручную - это более гибкий способ,
снижающий вероятность возникновения беспорядка.

Кроме того, клиент Docker способен принимать входные данные из стандартного потока ввода `STDIN`, если 
в команде указан аргумент `-` вместо контекста создания образа. Входными данными может быть либо 
Dockerfile без контекста (например,<br/> `docker build - < Dockerfile`), либо архивный файл, содержащий 
контекст, в том числе и Dockerfile (например,<br/>`docker build - < context.tar.gz`). Архивные файлы могут
передаваться в формате `tar.gz`, `xz`, или `bzip2`.

Размещение файла Dockerfile внутри контекста может быть указано с помощью аргумента `-f`
(например,<br/>`docker build -f dockerfile/Dockerfile.debug .`) Если нет прямого указания, то Docker попытается
найти файл с именем Dockerfile в корневом каталоге контекста.

> **Использование файла .dockeringnore**
> 
> Для удаления ненужных файлов из контекста создания образа можно воспользоваться файлом `.dockerignore`.
> Этот файл должен содержать имена исключаемых файлов, разделенных символами перехода на новую строку.
> Допускаются символы шаблнов `*` и `?.`. Например, можно сформировать `.dockerignore` со следующим содержимым:
> 
> `.git` `1`<br/>
> `*/.git` `2`<br/>
> `*/*/.git` `3`<br/>
> `*.sw?` `4`<br/>
> 
> `1` Из контекста исключается файл или каталог .git в корневом каталоге контекста создания образа, но при этом
> в контекст включается такой файл в любом подкаталоге (таким образом `.git` исключается, но `dir1/.git1` включается).<br/>
> `2` Из контекста исключается файл или каталог `.git`, расположенный в подкаталоге одним уровнем ниже корневого
> каталога (таким образом `dir1/dir2/.git` исключается, но `.git` и `dir1/dir2/.git` включаются).<br/>
> `3` Из контекста исключается файл или каталог `.git`, расположенный в подкаталоге двумя уровнями ниже корневого
> каталога (таким образом `dir1/dir2/.git` исключается, но, `.git` и `dir1/.git` включаются).<br/>
> `4` Из контекста исключаются файлы `test.swp`, `test.swo`, и `bla.swp`, но в контексте остается файл `dir1/test.swp`.

Не поддерживаются более сложные регулярные выражения, такие как `[A-Z]*`.

### Уровни образа

Способ создания образов Docker часто ставит в тупик неопытных пользователей. Каждая инструкция в Dockerfile
приводи к появлению нового _уровня (layer)_ образа, который также может участвовать в запуске контейнера.<br>
Новый уровень создается во время запуска контейнера с использованием образа предыдущего уровня при выполнении 
соответствующих инструкций Dockerfile и с сохранением нового образа. После успешного завершения выполнения 
инструкции Dockerfile вспомогательный контейнер удаляется, если в команде не был задан аргумент `--rm=false`.<br/>
Так как результатом выполнения каждой инструкции является создание статического образа - в сущности, это файловая
система и некоторые метаданные, - все активные процессы в данной инструкции будут завершены. Поэтому, несмотря на 
возможность инициализации в инструкции `RUN` долговременных процессов, подобных демонам СУБД и SSH, любые 
активные процессы прекратят свою работу при обработке следующей инструкции или запуске контейнера.<br/>
Если необходим сервис или процесс, запускаемый вместе с контейнером, его следует инициализировать с помощью
инструкции `ENTRYPOINT` или `CMD`.<br/>

Весь набор уровней, формирующих образ, можно увидеть, выполнив команду `docker history`:

```shell
$ docker history symfony_nginx
IMAGE          CREATED       CREATED BY                                      SIZE      COMMENT
d33cb3de286f   7 days ago    /bin/sh -c #(nop)  CMD ["nginx" "-g" "daemon…   0B        
d52d39e9f543   7 days ago    /bin/sh -c #(nop) WORKDIR /var/www/symfony      0B        
669e407cd748   7 days ago    /bin/sh -c #(nop)  EXPOSE 443                   0B        
fb0cb47e52c1   7 days ago    /bin/sh -c #(nop)  EXPOSE 80                    0B        
bc66d874522b   7 days ago    |6 DEBIAN_FRONTEND=noninteractive PAGESPEED_…   329kB     
30882c991da0   7 days ago    |6 DEBIAN_FRONTEND=noninteractive PAGESPEED_…   0B        
49f67db82b0e   7 days ago    |6 DEBIAN_FRONTEND=noninteractive PAGESPEED_…   323MB     
a55cc3f932bd   7 days ago    |6 DEBIAN_FRONTEND=noninteractive PAGESPEED_…   138MB     
3651fb2295a1   7 days ago    |6 DEBIAN_FRONTEND=noninteractive PAGESPEED_…   244MB     
42594e93909b   7 days ago    /bin/sh -c #(nop)  ARG RESTY_CONFIG_OPTIONS=…   0B        
a48457608ae2   7 days ago    /bin/sh -c #(nop) COPY file:eebef832a2c8b81b…   193B      
e197c0b79f13   7 days ago    /bin/sh -c #(nop)  ARG TERM=xterm-color         0B        
fd05bb596cad   7 days ago    /bin/sh -c #(nop)  ARG DEBIAN_FRONTEND=nonin…   0B        
42a8a0bce0b4   7 days ago    /bin/sh -c #(nop)  ARG PAGESPEED_VERSION=1.1…   0B        
49eb2c8d3e89   7 days ago    /bin/sh -c #(nop)  ARG RESTY_OPENSSL_VERSION…   0B        
d2473112a6cc   7 days ago    /bin/sh -c #(nop)  ARG RESTY_VERSION=1.13.6.2   0B        
5ddf6ebdcdb4   2 weeks ago   /bin/sh -c #(nop)  CMD ["bash"]                 0B        
<missing>      2 weeks ago   /bin/sh -c #(nop) ADD file:084c8b3d38d578aa3…   101MB  
```

Если создание образа завершилось неудачно, то может оказаться полезным запуск уровня, предшествующего ошибке.
Например, имеется следующий Dockerfile:
```dockerfile
FROM busybox:latest

RUN echo "This should work"
RUN /bin/bash -c echo "This won't"
```

Попробуем создать образ:
```shell
$ docker build -t echotest .
Sending build context to Docker daemon  2.048kB
Step 1/3 : FROM busybox:latest
latest: Pulling from library/busybox
24fb2886d6f6: Pull complete 
Digest: sha256:f7ca5a32c10d51aeda3b4d01c61c6061f497893d7f6628b92f822f7117182a57
Status: Downloaded newer image for busybox:latest
 ---> 16ea53ea7c65
Step 2/3 : RUN echo "This should work"
 ---> Running in a05bf0a07ece
This should work
Removing intermediate container a05bf0a07ece <- удаляется временный контейнер
 ---> 4f782ec7415f
Step 3/3 : RUN /bin/bash -c echo "This won't"
 ---> Running in 2d72080a9026
/bin/sh: /bin/bash: not found
The command '/bin/sh -c /bin/bash -c echo "This won't"' returned a non-zero code: 127
```

Несмотря на то что в нашем примере причина возникновения критической ошибки вполне очевидна, можно запустить 
образ, созданный из последнего успешно сформированного уровня, для отладки ошибочной инструкции. Обратите 
внимание на использование для этой цели идентификатора последнего образа (4f782ec7415f), а не последнего контейнера
(2d72080a9026):

```shell
$ docker run -it 4f782ec7415f
/ # /bin/bash -c "echo hmm"
sh: /bin/bash: not found
/ # /bin/sh -c "echo ahh!"
ahh!
/ # exit
```

Проблема становится гораздо более понятной: в образ busybox не включена командная оболочка `bash`.

### Кэширование

Для ускорения создания образов Docker выполняет кэширование каждого уровня. Кэширование очень важно
для повышения эффективности рабочих операций, но не всего его применение имеет смысл. Кэширование 
используется для инструкций при следующих условиях:

- в кэше была обнаружена предыдущая инструкция;
- в кэше имеется уровень, который имеет в точности ту же инструкцию и предшествующий родительский уровень
  (даже случайные пропуски могут сделать кэш некорректным).

Кроме того, для инструкций `COPY` и `ADD` кэш считается некорректным, если изменилась контрольная сумма или 
метаданные любого файла.<br/>
Это означает, что для сохраняемых в кэше инструкций `RUN` не гарантируется получение одинакового результата
при многократных повторных вызовах этих инструкций. Будьте особо внимательны, используя вызовы из кэша
для загрузки файлов, выполнения команды `apt-get update` и/или клонирование репозиториев исходного кода.

Чтобы запретить кэширование, можно выполнить команду `docker build` с аргументом `--no-cache`. Также 
можно добавить или заменить инструкцию перед строкой, в которой необходимо запретить кэширование, поэтому
иногда в файле Dockerfile встречаются строки, подобные следующей:
```dockerfile
ENV UPDATED_ON "14:12 17 February 2021"
RUN git clone...
```

Я не рекомендую применять такой способ, так как он может привести в полное замешательство всех, кто будет
в дальнейшем использовать данный образ, особенно если дата создания образа отличается от указанной в 
вышеприведенной строке Dockerfile.

### Базовые образы

При создании собственных образов необходимо выбрать один из базовых образов в качестве отправного пункта.
Выбор велик, поэтому стоит уделить время на изучение разнообразных достоинств и недостатков каждого базового
образа.<br/>

В идеальном случае создание нового образа вообще не потребуется - можно просто использовать существующий 
образ, объединив с ним свои конфигурационные файлы и/или данные. Во многих случаях такой подход применим 
для широко распространенного прикладного ПО, например для СУБД и веб-серверов, для которых доступны
готовые официальные образы. Вообще говоря, гораздо лучше воспользоваться официальным образом, чем пытаться
сформировать собственный - вам предлагается успешный результат работы людей, которые обладают солидным 
опытом организации работы ПО внутри контейнеров. Если официальный образ не подходит для вашей работы 
по некоторой конкретной причине, то попробуйте сформулировать эту причину как тему для обсуждения 
в исходном проекте, и наверняка найдутся пользователи, встречавшиеся с подобными проблемами и знающие, 
как их решить.<br/>

Если нужен образ для управления приложением, написанным вами, сначала попытайтесь поискать официальный
базовый образ для используемого языка или программной среды (например, Go или Ruby On Rails). Достаточно
часто можно воспользоваться различными образами для сборки и для распространения собственного ПО (например
для компиляции и сборки Java-приложения можно воспользоваться образом `java:jdk`, а распространять полученный
JAR-файл лучше с помощью более компактного образа `java:jre`, из которого исключены ненужные инструменты
компиляции и сборки). Некоторые другие официальные образы (такие как `node`) также представлены специализированными
компактными вариантами без инструментальных средств разработки и заголовочных файлов.<br/>

Иногда возникает потребность в использовании небольшого, но полноценного дистрибутива Linux. Если
действительно необходим предельный минимализм, рекомендуется обратить внимание на образ `alpine` размером
всего 5 Мб, при этом содержащий мощный менеджер пакетов для простой установки приложений и инструментальных средств.
Если нужен образ с более широкими возможностями, я обычно пользуюсь одним из образов `debian`, которые по размеру 
намного меньше образов самого популярного дистрибутива `ubuntu`, но пакетная база у них одна и та же. 
Кроме того, для организаций, постоянно использующих конкретный дистрибутив Linux, с большей вероятностью
найдется подходящий Docker-образ. Лучше потратить некоторое время на поиск, чем переходить на новый дистрибутив,
с которым сотрудники не знакомы, а системные администраторы не имеют опыта его сопровождения. <br/>

В большинстве случаев нет необходимости тратить время на поиски образов наименьшего размера. Помните, что базовые 
уровни совместно используются различными образами, поэтому если вы уже работаете с образом `ubuntu:14.04` и загружаете
из репозитория Hub образ, основанный на `ubuntu`, то фактически скачиваются только изменения, а не весь образ
целиком. Тем не менее образы минимальных размеров, несомненно, обладают большим преимуществом, когда 
требуется быстро развертывание и простое сопровождение распространение.<br/>

Размер образа можно уменьшить до предельной величины и формировать образы только из бинарных файлов. Для
этого необходим Dockerfile из специального образа `scratch` (абсолютна пустая файловая система). Бинарные 
файлы просто копируются в файловую систему создаваемого образа, а соответствующие инструкции `CMD` 
записываются в Dockerfile. Для бинарных файлов нужно включить в образ все требуемые библиотеки (без
динамического связывания) и исключить возможность вызова внешних команд. Также следует помнить, что бинарные
файлы должны быть скомпилированы для архитектуры контейнера, которая может отличаться от архитектуры компьютера,
на которой будет работать Docker-клиент.

Несмотря на большую привлекательность минималистического подхода, следует отметить, что он может привести 
к созданию сложной ситуации при отладке и в процессе сопровождения - в образе `bysybox` не так уж много рабочих
инструментов, а при использовании `scratch` недоступна даже командная оболочка.

> **Реакция синтеза**
> 
> Еще одним интересным вариантом основного образа является `phusion/beseimage-docker`. Разработчики
> Phusion создали этот образ как "ответную реакцию" на официальный образ Ubuntu, в котором по их заявлению
> отсутствуют некоторые весьма важные сервисы. Среди основных разработчиков Docker нет единого мнения 
> относительно точки зрения авторов Phusion, поэтому продолжаются дискуссии в блогах, IRC-каналах и твиттере.<br/>
> 
> Основные пункты разногласий перечислены ниже:
> * необходимость сервиса `init`. С точки зрения Docker каждый контейнер должен запускать только одно приложение
> и в идеальном случае должен представлять собой единственный процесс. Если имеется единственный процесс, то сервис
> `init` не нужен. Основной аргумент авторов Phusion: отсутствие сервиса `init` может привести к заполнению контейнера
> процессами-зомби, то есть процессами, не завершенными корректно их родительскими процессами, или принудительно 
> прерванными в срочном порядке процессом-супервизором. Это правильный довод, но в контейнере процессы-зомби могут
> возникать только из-за ошибок в коде приложения, и подавляющее большинство пользователей вообще не должно сталкиваться
> с такой проблемой, но если она возникла, то наилучшим решением будет исправление ошибок в коде;<br/>
> 
> 
> * работа демона `cron`. Основные образы `ubuntu` и `debian` по умолчанию не запускают демон `cron`, а в образе 
> `phusion` демон работает. Авторы Phusion обосновывают это тем, что многие приложения зависимы от `cron`, поэтому 
> его функционирование крайне необходимо. Точка зрения команды Docker (и я готов с ней согласиться): демон `cron`
> должен запускаться только в том случае, если приложение действительно зависит от него;
> 
> 
> * демон `SSH`. В большинстве основных образов сервис `SSH` по умолчанию не устанавливается и не запускается.
> Обычный способ вызова любой командной оболочки - использование команды `docker exec`, что позволяет избежать
> запуска лишнего процесса в каждом создаваемом контейнере. Казалось бы, что авторы Phusion согласны с таким 
> подходом, поэтому запретили запуск демона `SSH` по умолчанию, но из-за наличия кода демона и соответствующих
> библиотек его поддержки размер их образа существенно увеличен.

Подводя итог, могу порекомендовать использование основного образа Phusion, если существует особая необходимость
запуска в контейнере многочисленных процессов, демонов `cron` и `ssh`. В противном случае лучше воспользоваться
основными образами из официальных репозиториев Docker, такими как `ubuntu:14.04` и `debian`.

> **Пересборка образов**
> 
> Следует отметить, что при запуске команды `docker build` Docker считывает инструкцию `FROM` и пытается скачать
> заданный образ, если его нет в локальной системе. Если такой образ существует локально, Docker использует
> его без проверки доступности новой версии. Это означает, что команда `docker build` не может гарантировать,
> что вызываемый образ соответствует самой новой версии, поэтому необходимо явно выполнить команду `docker pull`
> для всех родительских образов или удалить их, чтобы команда `docker build` загрузила самые новые их версии.
> Это становится особенно важным при обновлениях, касающихся безопасности, широко используемых основных образов,
> таких как `debian`.

### Инструкции Dockerfile

В этом разделе кратко описаны различные инструкции, предназначенные для использования в файлах Dockerfile.
Мы не будем углубляться в подробности, отчасти из-за того, что эти инструкции продолжают изменяться и 
корректироваться, и информация о них может не вполне соответствовать действительности, отчасти потому, 
что абсолютно полная и точная документация по инструкциям доступна на [сайте Docker](http://docs.docker.com/reference/builder/).
Комментарии в файлах Dockerfile записываются с помощью символа `#` в самом начале строки.

> **Формат exec и формат командной оболочки**
> 
> В некоторых инструкциях (`RUN`, `CMD` и `ENTRYPORIN`) допускается использование как формата командной оболочки,
> так и формата `exec`. Формат `exec` принимает JSON-массив (например, `["executable", "param1", "param2"]`),
> предполагая, что первый элемент массива является именем выполняемого файла, а остальные элементы
> представляют параметры, передаваемые при запуске. Формат командной оболочки - строка произвольной формы,
> передаваемая для интерпретации в `/bin/sh -c`. Используйте формат `exec`, чтобы избежать случайного 
> искажения строк командной оболочки, или в тех случаях, когда образ не содержит `/bin/sh`.

Для использования в файлах Dockerfile доступны описанные ниже инструкции.

**ADD**<br/>
Копирует файлы из контекста создания или из удаленных URL-ссылок в создаваемый образ. Если архивный файл
добавляется из локального пути, то он будет автоматически распакован. Так как диапазон функциональности 
инструкции `ADD` достаточно велик, в общем случае лучше воспользоваться более простой командой `COPY`
для копирования файлов и каталогов в локальном контексте создания или инструкциями `RUN` с запуском `curl`
или `wget` для загрузки удаленных ресурсов (с сохранением возможности обработки и удаления результатов загрузки
в той же самой инструкции).


**CMD**<br/>
Запускает заданную инструкцию во время инициализации контейнера. Если была определена инструкция `ENTRYPOINT`,
то заданная здесь инструкция будет интерпретироваться как аргумент для `ENTRY POINT` (в этом случае необходимо
использовать формат `exec`). Инструкция `CMD` замещается любыми аргументами, указанными в команде `docker run`
после имени образа. В действительности выполняется только самая последняя инструкция `CMD`, а все предыдущие
инструкции `CMD` будут отменены (в том числе и содержащиеся в основных образах).


**COPY**<br/>
Используется для копирования файлов из контекста создания в образ. Имеется два формата: `COPY источник цель` и<br/>
`COPY ["источник", "цель"]` - оба копируют файл или каталог из 'источник' в контексте создания в 'цель' внутри 
контейнера. Формат JSON-массива обязателен, если путь содержит пробелы. Можно использовать шаблонные символы
для определения нескольких файлов или каталогов. Следует обратить особое внимание на невозможность указания
путей 'источника', расположенных вне пределов контекста создания (например, нельзя указать для копирования файл
`../another_dir/myfile`)


**ENTRYPOINT**<br/>
Определяет выполняемый файл (программу и аргументы по умолчанию), запускаемые при инициализации контейнера. В эту 
выполняемую программу передаются как аргументы любые инструкции `CMD` или аргументы команды `docker run`, записанные
после имени образа. Инструкции `ENTRYPOINT` часто используются для организации скриптов запуска, которые инициализируют
переменные и сервисы перед обработкой всех передаваемых в образ аргументов.

**ENV**<br/>
Определяет переменные среды внутри образа. На эти переменные можно ссылаться в последующих инструкциях:
```dockerfile
ENV MY_VERSION 1.3
RUN apt-get install -y mypackage=$MY_VERSION
```
Определенные в этой инструкции переменные будут доступными также и внутри образа.


**EXPOSE**<br/>
Сообщает механизму Docker о том, что в данном контейнере будет существовать процесс, прослушивающий заданный порт
или несколько портов. Механизм Docker использует эту информацию при установлении соединения между контейнерами или 
при открытии портов для общего доступа при помощи аргумента `-P` в команде `docker run`. Но сама по себе инструкция
`EXPOSE` не оказывает никакого воздействия на сетевую среду.


**FROM**<br/>
Определяет основной образ для файла Dockerfile. Все последующие инструкции выполняют операции поверх заданного
образа. Основной образ определяется в формате `IMAGE:TAG`. При отсутствии тега по умолчанию полагается `latest`,
но я настоятельно рекомендую всегда явно указывать тег конкретной версии, чтобы избежать неприятных неожиданностей.
Эта инструкция обязательно должна быть самой первой в Dockerfile.


**MAINTAINER**<br/>
Определяет метаданные об авторе "Author" для создаваемого образа в заданной строке. Извлечь эти метаданные 
можно с помощью команды `docker inspect -f {{.Author}} IMAGE`. Обычно используется для записи имени автора образа
и его контактных данных.


**ONBUILD**<br/>
Определяет инструкцию, которая должна выполняться позже, когда данный образ будет использоваться как основной 
уровень для другого образа. Это может оказаться полезным при обработке данных, добавляемых в образ-потомок
(например, это может быть инструкция копирования дополнительного кода из заданного каталога и запуска скрипта
сборки, обрабатывающего скопированные данные).


**RUN**<br/>
Запускает заданную инструкцию внутри контейнера и сохраняет результат.


**USER**<br/>
Задает пользователя (по имени или по идентификатору UID) для использования во всех последующих инструкциях
`RUN`, `CMD`, `ENTRYPOINT`. Отметим, что идентификаторы UID одинаковы на хосте и в контейнере, но имена пользователей
могут присваиваться различным идентификаторам UID, что может приводить к затруднениям при установке прав доступа.


**VOLUME**<br/>
Объявляет заданный файл или каталог как том. Если такой файл или каталог уже существует в образе, то он копируется
в том при запуске контейнера. Если задано несколько аргументов, то они интерпретируются как определение нескольких
томов. Из соображений обеспечения безопасности и сохранения переносимости нельзя определить каталог хоста как том 
внутри файла Dockerfile.


**WORKDIR**<br/>
Определяет рабочий каталог для всех последующих инструкций `RUN`, `CMD`, `ENTRYPOINT`, `ADD`, `COPY`. Инструкцию
можно использовать несколько раз. Допускается указание относительных путей, при этом итоговый путь определяется
относительно ранее указанного рабочего каталога `WORKDIR`.

## Установление связи контейнеров с внешним миром
Допустим, вы запустили веб-сервер внутри контейнера. Но как обеспечить связь сервера с внешним миром? Ответ прост - 
открыть нужные порты для общего доступа с помощью аргументов `-p` или `-P` в команде запуска. Такая команда 
перенаправляет порты хоста в контейнер. Например:

```shell
$ docker run -d -p 8000:80 nginx
Unable to find image 'nginx:latest' locally
latest: Pulling from library/nginx
...

$ curl localhost:8000
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
```

Аргумент `-p 8000:80` сообщил механизму Docker о необходимости перенаправления порта 8000 хоста на порт 80 в контейнере.
В качестве альтернативы при использовании аргумента -P механизм Docker должен автоматически выбрать свободный порт
для перенаправления с хоста в контейнер. Например:

```shell
$ ID=$(docker run -d -P nginx)
$ docker port $ID 80
0.0.0.0:49156
:::49156                                                                                                                                                 main    14:14:32  
$ curl localhost:49156
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
```

Главное преимущество использование аргумента -P заключается в устранении дополнительного уровня ответственности
за корректное назначение портов, что особенно важно при наличии нескольких контейнеров с портами, открытыми
для общего доступа. Чтобы определить номер портов, назначенные механизмом Docker, можно выполнить команду 
`docker port`.

## Соединение между контейнерами

Соединения (_links_) механизма Docker - простейший способ обеспечения обмена информацией между контейнерами
на одном хосте. При использовании принятой по умолчанию сетевой модели Docker обмен данными между контейнерами
будет происходить во внутренней сети Docker, то есть все коммуникационные операции останутся невидимыми из сети хоста.


Соединения инициализируются с помощью аргумента `--link CONTAINER:ALIAS` в команде `docker run`, <br/>
где `CONTAINER` - имя контейнера-адресата (_link container_), а `ALIAS` - локальное имя, используемое внутри
управляющего контейнера для обращения к контейнеру-адресату.


Кроме того, при использовании соединения Docker внутреннее имя и идентификатор контейнера-адресата будут добавлены
в файле `/etc/hosts` в управляющем контейнере, что позволит обращаться по этому имени к контейнеру-адресату из
управляющего контейнера.


Далее Docker создает в управляющем контейнере набор переменных среды, предназначенных для упрощения диалога с 
контейнером-адресатом. Например, при создании контейнера Redis и установлении соединения с ним:

```shell
$ docker run -d --name myredis redis 
155fcebf7e12fbb86e7d1f0a87a0e419968a5194c6c3485c723b987466bbc066
$ docker run --link myredis:redis debian env
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=75eaaf378556
REDIS_PORT=tcp://172.17.0.2:6379
REDIS_PORT_6379_TCP=tcp://172.17.0.2:6379
REDIS_PORT_6379_TCP_ADDR=172.17.0.2
REDIS_PORT_6379_TCP_PORT=6379
REDIS_PORT_6379_TCP_PROTO=tcp
REDIS_NAME=/xenodochial_satoshi/redis
REDIS_ENV_GOSU_VERSION=1.12
REDIS_ENV_REDIS_VERSION=6.2.6
REDIS_ENV_REDIS_DOWNLOAD_URL=http://download.redis.io/releases/redis-6.2.6.tar.gz
REDIS_ENV_REDIS_DOWNLOAD_SHA=5b2b8b7a50111ef395bf1c1d5be11e6e167ac018125055daa8b5c2317ae131ab
HOME=/root
```

Мы можем видеть, что Docker создает переменные среды с префиксом `REDIS_PORT`, содержащие информацию,
необходимую для установления соединения с контейнером Redis. Некоторые значения кажутся избыточными, поскольку
нужная информация уже содержится в имени переменной. Тем не менее все переменные и их значения в любом случае
полезны, хотя бы как своеобразная форма документации. 

Кроме того, Docker импортировал несколько переменных среды из контейнера адресата, их можно отличить по префиксу
`REDIS_ENV`. Такое функциональное свойство может быть весь удобным, но о нем следует помнить, когда вы используете
переменные среды для хранения секретной информации, например маркеров прикладных программных интерфейсов или 
паролей к базам данных.

По умолчанию контейнеры могут обмениваться информацией друг с другом вне зависимости от того, было ли установлено
соединение в явной форме. Если нужно запретить эту возможность, воспользуйтесь аргументами `--icc=false` и `--iptables`
при запуске демона Docker. В этом случае при установлении соединения Docker будет применять любые правила Iptables,
чтобы разрешить контейнерам обмен информацией через любые порты, которые были объявлены открытыми.

К сожалению, соединения Docker в их текущем состоянии имеют ряд недостатков. Возможно, самым существенным недостатком
является их статичность - несмотря на то что при перезапуске контейнеров соединения должны сохраняться, они не обновляются,
если контейнер-адресат был изменен заменен. Кроме того, контейнер-адресат обязательно должен быть инициализирован раньше
управляющего контейнера, то есть двунаправленное соединение установить невозможно.

## Управление данными с помощью томов и контейнеров данных

Резюмируя сказанное ранее, отметим, что _тома (volumes)_ Docker - это каталоги, которые не являются частью
файловой системы UnionFS конкретного контейнера а представляют собой обычные каталоги в файловой системе хоста,
но могут быть _смонтированы как отдельные файловые системы (bind mounting)_ внутри контейнера.

Существуют три различных способа инициализации томов. Важно хорошо понимать различия между этими способами.
Во-первых, можно объявить том при запуске контейнера с помощью флага `-v`:

```shell
$ docker run -it --name container-test -h CONTAINER -v /data debian /bin/bash
root@CONTAINER:/# ls /data
root@CONTAINER:/# 
```

Здесь каталог `/data` внутри контейнера станет томом. Любые файлы, которые данный образ сохранил в каталоге `/data`,
копируются на этот том. Мы можем проверить место расположения данного тома в файловой системе хоста, выполнив
команду `docker inspect` на хосте из новой командной оболочки:

```shell
$ docker inspect -f {{.Mounts}} container-test
[{volume 2cd... /var/snap/docker/common/var-lib-docker/volumes/2cd.../_data /data local  true }]
```

Здесь том `/data/` в контейнере представляет собой просто ссылку на каталог<br/>
`/var/snap/docker/common/var-lib-docker/volumes/2cd.../_data` в файловой системе хоста. Чтобы проверить это
на практике, можно добавить файл в указанный каталог хоста:

```shell
$ sudo touch /var/snap/docker/common/var-lib-docker/volumes/2cd.../_data/test-file
```

Этот файл сразу же можно увидеть внутри контейнера:

```shell
root@CONTAINER:/# ls /data/
test-file
```

Второй способ - объявление тома с помощью инструкции `VOLUME` в файле Dockerfile:

```dockerfile
FROM debian:latest
VOLUME /data
```

Результат будет в точности тот же самый, что при использовании ключа `-v` в команде `docker run`.

> **Установка прав доступа к тому в файле Dockerfile**
> 
> Достаточно часто для тома требуются определение его владельца и установка прав доступа или инициализация
> тома с помощью некоторых данных по умолчанию или файлов конфигурации. Очень важно помнить о том, что любая
> инструкция, расположенная после инструкции `VOLUME` в Dockerfile, не произведет никаких изменений в этом 
> томе. Например, следующий Dockerfile будет работать совершенно не так как ожидалось:
> 
>```dockerfile
>FROM debian:latest 
>RUN useradd foo
>VOLUME /data
>RUN touch /data/x
>RUN chown -R foo:foo /data
>```
> Подразумевалось, что команды `touch` и `chown` будут выполнены в файловой системе образа, но в действительности
> они запускаются в томе временного контейнера, используемого для создания соответствующего уровня. Этот
> том будет удален после выполнения перечисленных команд, что делает две последние инструкции бессмысленными.<br/>
> Следующий Dockerfile будет работать правильно:
>```dockerfile
>FROM debian:latest
>RUN useradd foo
>RUN mkdir /data && touch /data/x
>RUN chown -R foo:foo /data
>VOLUME /data
>```
>При запуске контейнера из этого образа Docker скопирует все файлы из каталога тома в образе в соответствующей 
> том контейнера. Но этого не произойдет если, в качестве тома задан существующий каталог хоста (чтобы 
> случайно не уничтожить файлов, хранящихся в файловой системе хоста).<br/>
> Если по какой-либо причине невозможно определить владельца и установить права доступа в инструкции `RUN`,
> то воспользуйтесь инструкцией `CMD` или `ENTRYPOINT`, выполняющей соответствующий скрипт после создания 
> контейнера.

Третий способ состоит в расширении аргумента `-v` команды `docker run` с явным указанием связываемого каталога
хоста в формате `-v HOST_DIR:CONTAINER_DIR`. Этот способ нельзя использовать в Dockerfile (т.к он нарушает 
принцип переносимости и создает угрозу безопасности). Например:
```shell
$ docker run -v /home/user/data:/data debian ls /data
```

Здесь каталог файловый системы хоста `/home/user/data` монтируется как `/data` в контейнере. Все файлы,
уже существующие в каталоге `/home/user/data`, становятся доступными внутри контейнера. Если каталог `/data`
ранее существовал в контейнере, то его содержимое будет скрыто созданным томом. В отличии от других вариантов
вызова, никакие файлы из образа не копируются в том, и этот том не будет удален механизмом Docker (т.е команда
`docker rm -v` не удаляет том, который монтируется на каталог, указанный пользователем).

> **Монтирование каталогов как файловых систем**</br>
> Использование явно заданного каталога хоста в томе (синтаксис с ключом `-v HOST_DIR:CONTAINER_DIR`) часто называют
> монтированием каталогов как файловых систем (bind mounting). Это не совсем правильно, поскольку с формальной
> точки зрения все тома являются каталогами, смонтированными как файловые системы. Разница лишь в том, что 
> в одном случае точка монтирования указывается явно, а в другом она скрыта от пользователя в каталоге, 
> принадлежащим механизму Docker.

### Совместное использование данных

Синтаксис с использованием ключа `-v HOST_DIR:CONTAINER_DIR` очень удобен для совместного использования файлов хостом
и одним или несколькими контейнерами. Например, файлы конфигурации могут храниться на хосте и монтироваться 
внутри контейнеров, создаваемых из однотипных образов.

Также можно совместно пользоваться одними и теми же данными в нескольких контейнерах, если указать 
ключ `--volumes-from CONTAINER` в команде `docker run`. Например, новый контейнер, который имеет доступ к томам
контейнера, созданного в предыдущем примере, можно получить следующим образом:
```shell
$ docker run -it -h NEWCONTAINER --volumes-from container-test debian /bin/bash
root@NEWCONTAINER:/# ls /data
test-file
root@NEWCONTAINER:/# 
```

Важно отметить, что этот способ работает вне зависимости от того, активен ли в текущий момент контейнер, 
содержащий тома (в нашем примере это `container-test`). Том невозможно удалить, пока существует хотя бы один
контейнер, установивший связь с этим томом.

### Контейнеры данных

На практике широко распространено создание _контейнеров данных (data containers)_, единственной
целью которых является обеспечение совместного использования данных несколькими контейнерами. Главное преимущество
такого подхода состоит в предоставлении удобного пространства имен для томов, загружаемых про с помощью ключа 
`--volumes-from` в команде `docker run`.

Например можно создать контейнер данных для СУБД PostgreSQL, выполнив следующую команду:

```shell
$ docker run --name dbdata postgres echo "Data-only container for postgres"
```
Здесь создается контейнер из образа `postgres`, а все тома, определенные в этом образе, инициализируются до выполнения
команды `echo` и выхода (завершения команды `docker run` в целом). Нет необходимости оставлять контейнеры данных
в активном рабочем состоянии, так как это влечет за собой лишь ненужный расход ресурсов.

В дальнейшем мы можем пользоваться томами созданного контейнера данных, применяя аргумент `--volumes-from`. 
Например:

```shell
$ docker run -d --volumes-from dbdata --name db1 postgres
```

> **Образы для контейнеров данных**<br>
> Обычно нет необходимости в использовании для контейнеров данных 'минималистичных образов' типа `busybox` или 
> `scratch`. Просто используйте тот же образ, что и для контейнера, работающего с данными. Например, при использовании
> образа `postgres` для создания контейнера данных следует взять тот же образ при создании контейнера для СУБД PostgreSQL.<br>
> При использовании одного и того же образа не требуется дополнительное пространоство - можете быть уверены, что образ
> для "потребителя" уже загружен  или создан. Кроме того, возникает возможность ввести в контейнер некоторые 
> начальные данные, и обеспечивать корректность установки прав доступа.

### Удаление томов

Тома удаляются, только если:
- контейнер, содержащий тома, был удален командой `docker rm -v`
- в команду `docker run` был включен флаг `--rm`
- отсутствие контейнеров, установивших связь с удаляемыми томами
- удаляемому тому не соответствует какой-либо каталог файловой системы хоста (то есть при создании тома<br>не использовался
синтаксис с ключом -v `HOST_DIR:CONTAINER_DIR`).

В данное время это означает, что следует всегда быть особенно внимательным при запуске контейнеров со связанными
томами, в противном случае рабочий каталог Docker с большей вероятностью будет содержать "потерянные" файлы и каталоги
(так называемые 'сироты' - orphans), а что именно представляет каждый их них, определить сложно. В компании Docker
уже разрабатывают набор команд самого верхнего уровня для томов, которые позволяют выводить список томов, создавать,
просматривать содержимое и удалять тома независимо от контейнеров. Эти изменения ожидаются в версии 1.9, которая должна
выйти после публикации книги.

## Часто используемые команды Docker

В этом разделе приведено краткое (по сравнению с официальной документацией) и далеко не полное описание различных 
команд Docker. Главное понимание сосредоточено на командах, которые выполняются наиболее часто. Поскольку программная
среда Docker быстро изменяется и развивается, самую точную и подробную информацию об этих командах можно получить на сайте
Docker в разделе [официальной документации](#http://docs.docker.com). Синстаксис и аргументы команд здесь не рассматриваются
в подробностях (за исключением команды `docker run`). Для каждой команды имеется встроенная справка, которую можно 
вывести при помощи аргумента `--help` в конкретной команде или общей командой `docker help`.

> **Флаги с логическими значениями в командах Docker**
> Для большенства утилит командной строки Unix вы наверняка обнаружите флаги, не требующие какого-либо значения,
> например флаг `-l` в команде `ls -l`. Поскольку эти флаги либо присутсвтуют, либо отсутствуют, Docker определяет
> их как логические (boolean) флаги - что отличает Docker от большенства других утилит - и обеспечивает поддержку
> записи логического значения для флага в явной форме (таким образом, приемлемыми являются оба формата: `-f=true` и 
> `-f`). Кроме того, могут существовать флаги, значения которых по умолчанию равно как `true` так и `false` (и это
> изрядно сбивает с толку). В отличии от флагов с значением `false` по умолчанию, флаги со значением `true`, по 
> умолчанию считаются установленными, если они не указаны явно. Указание флага без авргумента дает тот же эффект, 
> что и присваение значения `true`, - флаг со значением `true` по умолчанию не отменяется аргументом с произвольным
> значением, единственный способ отмены флага со значением `true` - явная установка для него значения `false` (например,
> `-f=false`).<br>
> Чтобы определить значение флага по умолчанию, воспользуйтесь ключом `--help` для конкретной команды. Например:<br>
> ```shell
> $ docker logs --help
> Usage:  docker logs [OPTIONS] CONTAINER
> Fetch the logs of a container
> Options:
> --details        Show extra details provided to logs
> -f, --follow         Follow log output
>     --since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)
> -n, --tail string    Number of lines to show from the end of the logs (default "all")
> -t, --timestamps     Show timestamps
>     --until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)
> ```
> Отсюда видно, что аргументам `-f`, `--help` и `-t` по умолчанию присвоено значение `false`. <br>
> Чтобы лучше понять все сказанное выше, рассмотрим несколько конкретных примеров с аргументом `--sig-proxy` 
> (по умолчанию значение `true`) для команды `docker run`. Единственный способ отмены действия этого аргумента -
> явное присваение ему значения `false`. Например: <br>
> ```shell
> $ docker run --sig-proxy=false ...
> ```
> Ниже приведены команды, абсолютно равнозначные друг другу:
> ```shell
> $ docker run --sig-proxy=true ...
> $ docker run --sig-proxy ...
> $ docker run ...
> ```
> В случае с аргументом, значением которого по умолчанию является `false`, например `--read-only`, следующие команды
> изменят его значение на `true`: <br>
> ```shell
> $ docker run --read-only=true ...
> $ docker run --read-only ...
> ```
> Для данного аргумента его отсутствие в команде или явное присваение значения `false` равнозначно.<br>
> Кроме всего прочего, такой подход иногда становится источником в некотором роде "хитрого" поведения при использовании
> флагов, которые обычно вычисляются логике вычисления по короткой схеме (например, `docker ps --help=false`) будет
> работать как обычно, без вывова текста справки).

### Команда run

Ранее мы уже наблюдали выполнение команды `docker run` - эта команда запуска новых контейнеров. Поэтому на текущий момент
она является самой сложной командой и поддердживает обширный список возможных аргументов. Аргументы позволяют пользователям
конфигурировать процесс приведения образа в рабочее состояние, заменять параметры настройки из `Dockerfile`,
определять параметры конфигурации сети, устанавливать права доступа и назначать ресурсы для создаваемого контейнера.<br>
Следующие ключи управляют жизненным циклом контейнера и основным режимом его работы:

- `-a, --attach`
  - Подключает заданный поток (`STDOUT` и прочие) к терминалу. Если ключ не задан, то подключаются поток вывода 
  `stdout` и поток ошибок `stderr`. Если ключ не задан и при этом контейнер запускается в интерактивном режиме 
   (`-i`), то подключаетя еще и поток вывода `stdin`.<br>Несовместима с ключом `-d`.
  

- `-d, --detach`
  - Запускает контейнер в режиме "отключения от всех потоков". Команда запускает контейнер в фоновом режиме (background mode)
  и возвращает идентификатор (ID) конетйнера.


- `-i, --interactive`
  - Поддерживает доступность открытого потока `stdin` (даже если он не был подключен). Как правило, используется
  вместе с ключом `-t` для запуска контейнера в интерактивном режиме. Например:<br>
  ```shell
  $ docker run -it debian bash
  root@29b4abb13cf8:/# ls
  bin  boot  dev	etc  home  lib	lib64  media  mnt  opt	proc  root  run  sbin  srv  sys  tmp  usr  var
  
  $ docker run -i debian bash
  pwd   
  /
  whoami
  root
  ```

- `--restart`
  - Позволяет настроить образ действий при попытке Docker перезапустить остановленный контейнер. Аргумент `no` запрещает
  любые попытки перезапуска контейнера. При аргумента `always` попытки перезапуска выполняются в любом случае
  вне зависимости от состояния контейнера после выхода. Если задан аргумент `on-failure`, то попытки перезапуска
  выполняются для контейнера, завершившего работу с ненулевым статусом. В последнем случае может быть задан 
  дополнительный необязательный аргумент, определяющий максимальное количество попыток перезапуска (если этот 
  аргумент не задан, то попытки будут выполняться бесконечно). Например, команда<br>
  `docker run --restart on-failure:10 postgres` запускает контейнер `postgres`, и если контейнер завершает работу с 
  ненулевым кодом, то выполняются 10 попыток его перезапуска.


- `--rm`
  - Автоматически удаляет контейнер после завершения сеанса его работы (выхода). Несовместим с ключом `-d`.

  
- `-t, --tty`
  - Создает псевдоустройство TTY (терминал). Как правило, используется вместе с ключом `-i` для запуска 
  контейнера в интерактивном режиме.

Ниже описываются ключи для определения имен контейнеров и внутренних переменных их среды.

- `-e, --env`
  - Определяет переменные среды внутри контейнера. Например:
  ```shell
  $ docker run -e var1=val -e var2="val 2" debian env 
  PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
  HOSTNAME=0db0be62769b
  var1=val
  var2=val 2
  HOME=/root
  ```
  Также отметим, что имеется ключ `--env-file` для передачи переменных среды через заданный файл.


- `-h, --hostname`
  - Устанавливает для запускаемого контейнера заданное имя Unix-хоста. Например:
  ```shell
  $ docker run -h "myhost" debian hostname
  myhost
  ```


- `--name NAME`
  - Присваивает контейнеру имя `NAME`. В дальнейшем это имя может использоваться для обращения к данному контейнеру
  в других командах Docker.

Ключи описанные ниже, позволяют пользователю создавать и настраивать тома.

- `-v, --volume`
  - Существуют две формы записи этого аргумента для создания и настройки тома (файла или каталога внутри контейнера,
  являющийся частью файловой системы хоста, а не файловой системы UnionFS контейнера). Первая форма определяет
  только каталог внутри контейнера, а связываемый с ним каталог хоста выбирает механизм Docker. Вторая форма
  определяет как внутренний каталог контейнера, так и связываемый с ним каталог хоста.


- `--volumes-from`
  - Монтирует тома из заданного контейнера. Часто используются при работе с контейнерами данных 

Ниже приведены описания наиболее часто используемых ключей для настройки сетевой среды.

- `--expose`
  - Аналог инструкции `EXPOSE` из файла `Dockerfile`. Определяет номер порта или диапазон номеров портов,
  предназначенных для использования в контейнере, но в действительности не открывает каких-либо портов.
  Применение этого ключа имеет смысл только в сочетании с ключом `-P`, а так же при установленнии соединений между
  контейнерами.


- `--link`
  - Настраивает интерфейс частной закрытой сети для заданного контейнера.


- `-p, --publish`
  - "Публиует" порт данного контейнера, то есть делает его доступным с хоста. Если соответствующий порт хоста 
  не определен, то произвольным образом выбирается свободный порт с большим номером (за пределами диапазона 
  системных портов), который в дальнейшем можно узнать с помощью команды `docker port`. Так же жно определить
  интерфейс хоста, для которого объявляется данный порт.


- `-P, --publish-all`
  - Объявляет все порты, открываемые в контейнере, доступными на хосте. Для объявляемого порта произвольным
  образом выбирается свободный порт с большим номером . Чтобы увидеть установленные соответствия между портами,
  воспользуйтесь командой `docker port`.

Могут быть полезными некоторые ключи, предназначенные для более тонкой настройки сетевой среды. Но следует помнить
о том, что применение этих ключей потребует более глубокого понимания работы в сети и реализации ее поддержки в 
Docker.<br>
Кроме того, команда `docker run` имеет ряд ключей для управления привилегиями и функциональными возможностями 
контейнеров.<br>
Следующие ключи предназначены для безусловной замены параметров настройки, определенных в Dockerfile.

- `--entrypoin`
  - Определяет точку входа для запускаемого контейнера в соответствии с заданным аргументом, заменяя содержимое
  любой инструкции `ENTRYPOINT` из Dockerfile.


- `-u, --user`
  - Определяет пользователя, от имени которого выполняются команды. Может быть задано как символьное имя пользователя
  или как числовой идентификатор `UID`. Заменяет содержимое инструкции `USER` из Dockerfile.


- `-w, --workdir`
  - Устанавливает рабочий каталог в контейнере в соответствии с заданным путевым именем. Заменяет любые значения,
  определенные в файле Dockerfile.

### Управление контейнерами
Кроме команды `docker run`, существуют и другие команды `docker`, предназначенные для управления контейнерами 
на протяжении их жизненного цикла.

- `docker attach [OPTIONS] CONTAINER`
  - Команда `attach` позволяет пользователю наблюдать или взаимодействовать с основным процессом внутри контенера.
  Например:<br>
  ```shell
  $ ID=$(docker run -d debian sh -c "while true; do echo 'tick'; sleep 1; done;")
  $ docker attach $ID 
  tick
  tick
  tick
  ...
  ```
  Следует отметить, что использование комбинации клавиш **Ctrl+C** для выхода завершит наблюдаемый процесс
  и приведет к завершению работы контейнера.


- `docker create`
  - Создает контейнер из заданного образа, но не запускает его. Аргументы этой команды в основном те же, что и 
  для команды `docker run`. Чтобы запустить созданный контейнер, нужно выполнить команду `docker start`.


- `docker cp`
  - Позволяет копировать файлы между файловыми системами контейнера и хоста.


- `docker exec`
  - Запускает заданную команду внутри контейнера. Может использоваться для выполнения задач сопровождения или
  в качестве замены `ssh` при входе (регистрации) в контейнер. Например: <br>
  ```shell
  ID=$(docker run -d debian sh -c "while true; do sleep 1; done;")
  $ docker exec $ID echo "Hello"
  $ docker exec -it $ID /bin/bash
  root@b44bc9a59385:/# ls
  bin  boot  dev	etc  home  lib	lib64  media  mnt  opt	proc  root  run  sbin  srv  sys  tmp  usr  var
  root@b44bc9a59385:/# exit
  exit
  ```
  

- `docker kill`
  - Посылает сигнал основному процессу (PID=1) в контейнере. По умолчанию посылает сигнал `SIGKILL`, по которому
  выполняется немедленное завершение работы контейнера. Можно передать другой сигнал с помощью дополнительного
  аргумента `-s`. Возвращает идентификатор контейнера. Например:<br>
  ```shell
  $ ID=$(docker run -d debian bash -c \
    "trap 'echo caught' SIGTRAP; while true; do sleep 1; done;")
  $ docker kill -s SIGTRAP $ID
  2eb922c3c3d769adaa231da2a498d0973a1d30bdf233401f2be5a0409bc90b95
  $ docker logs $ID
  caught
  $ docker kill $ID
  2eb922c3c3d769adaa231da2a498d0973a1d30bdf233401f2be5a0409bc90b95
  ```


- `docker pause`
  - Временно приостанавливает все процессы внутри заданного контейнераю. Процессы не получают никаких сигналов 
  приостановки, следовательно, не могут быть полностью остановлены и завершены или удалены. Продолжить выполнение
  этих процессов можно с помощью команды `docker unpause`. Команда `docker pause` использует внутреннюю функциональную
  возможность приостановки (freezing) механизмы cgroups в ядре Linux. Эта команда значительно отличается от команды
  `docker stop`, которая полностью останавливает выполнение всех процессов и посылает процессам сигналы в явной форме.
  

- `docker restart`
  - Перезапускает один или несколько контейнеров. Можно считать приблизительным аналогом выполнения для заданных
  контейнеров команды `docker stop`, за которой сразу следует команда `docker start`. Имеется дополнительный 
  аргумент `-t`, определяющий интервал времени ожидания, необходимого для завершения работы контейнера, перед
  его остановом по сигналу `SIGTERM`.


- `docker rm`
  - Удаляет один или несколько контейнеров. Возвращает имена или идентификаторов успешно удаленных контейнеров.
  По умолчанию `docker rm` не удаляет существовующие тома. Аргумент `-f` позволяет удалять работающие контейнеры.
  С помощью аргумента `-v` можно удалить тома, созданные удаляемым контейнером (если эти тома не смонтированы на 
  каталоги и не используются другими контейнерами). Например, для удаления всех остановленных контейнеров нужно
  выполнить команду:
  ```shell
  $ docker rm $(docker ps -aq)
  b7a4e94253b3
  e33da73c275b
  f47074b60757
  ```


- `docker start`
  - Запускает остановленный контейнер (или несколько контейнеров). Может использоваться для повторного запуска
  остановленного контенера или для запуска контейнера, ранее созданного командой `docker create`, но никогда 
  не выполнявшегося.


- `docker stop`
  - Останавливает (но не удаляет) один или несколько контейнеров. После выполнения этой команды заданный 
  контейнер переходит в состояние "остановлен" ("завершен"). Дополнительный аргумент `-t` определяет интервал
  времени ожидания, необъодимого для завершения работы контейнера, перед его остановом по сигналу `SIGTERM`.


- `docker unpause`
  - Перезапускает контейнер, выполнение которого было приостановлено командой `docker pause`.
  > **Отключение от контейнеров**<br>
  > После подключения к контейнеру Docker при запуске его в интерактивном режиме или с помощью команды
  > `docker attach` этот контейнер будет полностью остановлен, если попытаться отключиться от него с помощью
  > комбинации клавиш **Ctrl+C**. Отключиться от контейнера без его останови можно с помощью комбинации клавиш
  > **Ctrl+P, Ctrl+Q**.<br>
  > Этот способ работает только при подключении в интерактивном режиме с использованием терминального устройства
  > TTY (то есть при использовании флагов `-i` и `-t` ).

### Информация о механизме Docker

Следующие команды используются для получения информации об установленной системе Docker и её использовании:
- `docker info`
  - Выводит различную информацию сисетме Docker и хосте, на котором она работает.


- `docker help`
  - Выводит информацию об использовании и справку по заданной команде. Аналогично выполнению команды с флагом `--help`.
  

- `docker version`
  - Выводит информацию о версии клиента и сервера Docker, а также о версии языка программирования Go, используемого
  при компиляции.

### Информация о контейнере
Следующие команды предоставляют информацию о работающих и остановленных контейнерах.

- `docker diff`
  - Показывет изменения в файлово системе контейнера о сравнению с файловой системой образа, который был 
  использован для запуска этого контейнера. Например:<br>
  ```shell
  $ ID=$(docker run -d debian touch /NEW_FILE)
  $ docker diff $ID
  A /NEW_FILE
  ```


- `docker events`
  - Выводит в реальном времени события от демона демону. Для выхода из этого режима используйте комбинацию 
  клавиш Ctrl-C


- `docker inspect`
  - Предоставляет подробную информацию о заданных контейнерах или образах. В основном это информация о конфигурации,
  включающая параметры настройки сети и параметры привязки томов. Аргумент -f используется для определения шаблонов
  языка Go при форматировании и фильтрации вывода.


- `docker logs`
  - Выводит журнал (logs) для контейнера. Выводится все, что было записано и потоки `STDERR` и `STDOUT` внутри 
  контейнера.


- `docker port`
  - Выводит список отображений открытых портов для заданного контейнера. Дополнительно могут быть заданы номер
  внутреннего порта контейнера и искомый протокол. Часто используется после выполнения команды<br>
  `docker run -P image` для получения списка назначенных портов. Например<br>
  ```shell
  $ ID=$(docker run -P -d redis)
  $ docker port $ID
  6379/tcp -> 0.0.0.0:49153
  6379/tcp -> :::49153

  $ docker port $ID 6379
  0.0.0.0:49153
  :::49153
  $ docker port $ID 6379/tcp
  0.0.0.0:49153
  :::49153
  ```
  

- `docker ps`
  - Предоставляет общую информацию о работающих контейнерах: имя, идентификатор, состояние. У этой команды большое
  количество разнообразных аргументов, среди которых наиболее важным является `-a`, позволяющий вывести информацию
  обо всех контейнерах, а не только о работающих в текущий момент. Также следует отметить аргумент `-q`, возвращающий
  только идентификаторы контейнеров, что очень удобно для организации потока вывода для других команд, например
  `docker rm`.


- `docker top`
  - Предоставляет информацию о процессах, выполняющихся внутри заданного контейнера. В действительности эта команда
  запускает утилиту Unix `ps` на хосте и выбирает для вывода процессы, выполняющиеся в заданном контейнере. Авргументы
  для этой команды совпадают с аргументами утилиты `ps`, и по умолчанию установлены аргументы `-ef` (но помните
  о необходимости сохранить поле идентификатора процесса `PID` при выводе результатов). Например:<br>
  ```shell
  $ ID=$(docker run -d redis)
  $ dcoker top $ID
  UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
  999                 28746               28725               0                   14:04               ?                   00:00:00            redis-server *:6379
  
  $ ps -f -u 999
  UID          PID    PPID  C STIME TTY          TIME CMD
  999        16991   16971  0 11:54 ?        00:00:12 redis-server *:6379
  999        28746   28725  0 14:04 ?        00:00:00 redis-server *:6379

  $ docker top $ID -axZ
  LABEL          PID  TTY STAT TIME COMMAND
  docker-default 9243 ?   Ssl  0:00 redis-server *:6379
  ```
  
### Работа с образами 
Следующие команды представляют собой инструменты для создания образов и работы с ними:

- `docker build`
  - Создает образ из файла Dockerfile


- `docker commit`
  - Создает образ из указанного контейнера. Эта команда иногда может быть полезной, тем не менее в большенстве 
  случаев предпочтительнее пользоваться командой `docker build`, которая с легкостью воспроизводится повторно.
  По умолчанию контейнеры временно приостанавливаются перед созданием образа, но приостановку можно отменить 
  